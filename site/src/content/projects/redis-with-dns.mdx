---
title: "Learning Redis by Building: A Hands-On DNS Cache Dashboard"
date: "2025-10-21"
description: "Building an interactive DNS caching dashboard with Python, Flask, and Redis to learn different Redis data structures like Hashes, Strings, Lists, and Sorted Sets."
tags:
  - Python
  - Flask
  - Redis
  - DNS
  - Caching
  - DevOps
repoUrl: "https://github.com/ramees-kr/redis-with-dns"
---

## Introduction: Learning Redis Through a Practical Project

I've found that the best way to learn is by doing. For my latest project, I decided to tackle something practical: building a DNS caching tool. Why? Because constantly hitting live DNS servers can be slow, and I wanted a hands-on way to understand one of the most popular tools in the DevOps arsenal: **Redis**.

This project turned into a full-blown **interactive web application** – a "tutorial dashboard" built with **Python**, **Flask**, and **Redis** – that not only performs DNS lookups but also visualizes exactly how different Redis data structures make it fast and efficient. If you're curious about caching, want to see Redis in action, or are just starting your own DevOps learning journey, this project might give you some ideas!

![Redis DNS Dashboard Screenshot](/images/projects/21102025-redis-with-dns.jpeg)
![Redis DNS Dashboard Screenshot](/images/projects/21102025-redis-with-dns2.jpeg)
![Redis DNS Dashboard Screenshot](/images/projects/21102025-redis-with-dns3.jpeg)

---

## The "How": Caching DNS with Multiple Redis Data Structures

The core idea is simple: when a user queries for a DNS record (`A`, `MX`, `TXT`, or `NS`), we first check Redis. If we find a valid, non-expired entry, we serve it instantly (a **cache hit**!). If not (a **cache miss**!), we perform the live lookup using the `dnspython` library, store the result in Redis with the _actual TTL_ from the DNS record, and then return it.

But where Redis really shines is _how_ we store different kinds of data. This project ended up using four different data structures:

1.  **Hashes for Success:** Successful DNS lookups, which might contain multiple records (like several IP addresses or MX servers), are stored perfectly in a **Redis Hash**. It's like a mini-database object, storing the records, the timestamp, and the record type all under one key (e.g., `dns:cache:google.com:A`).
2.  **Strings for Failure:** What about domains that don't exist (`NXDOMAIN`)? Querying them repeatedly is wasteful. We use simple **Redis Strings** for "negative caching," storing a key like `dns:nx:nonexistent.com:A` with a short, fixed TTL. It's a lightweight flag saying, "Don't bother looking this up again for a minute".
3.  **Lists for Recent Queries:** The dashboard shows the last 10 queries. A **Redis List** is perfect here. `LPUSH` adds the latest query to the front in O(1) time, and `LTRIM` keeps the list capped at 10 entries.
4.  **Sorted Sets for the Leaderboard:** To track the most popular domains, a **Sorted Set (`ZSET`)** is king. Every query triggers a `ZINCRBY` command. This single, atomic command increments the score for that domain and automatically keeps the set sorted by score. Fetching the Top 10 with `ZREVRANGE` is then trivial.

Here’s the core logic for updating and fetching the leaderboard:

```python
# In app.py, on every query (even failures):
# Increment the score for 'domain_name' by 1 in the set 'dns:popularity'
r.zincrby(POPULARITY_KEY, 1, domain_name)

# In the dashboard route (and /feature/zsets):
# Get ranks 0-9 (the top 10) in reverse order (highest score first)
leaderboard = r.zrevrange(POPULARITY_KEY, 0, 9, withscores=True)
```

This combination shows how you can pick the right Redis tool for each specific job within the same application.

---

## Key Takeaways / What I Learned

Building this was a fantastic learning experience, going way beyond just reading docs:

- **Choosing the Right Data Structure Matters:** Seeing why a Hash is better than multiple Strings for the cache, or why a Sorted Set beats a List for leaderboards, really makes the concepts stick.
- **Caching Isn't Just GET/SET:** Implementing negative caching and respecting dynamic TTLs from actual DNS records added layers of realism. We even added logic to clear the negative cache if a domain later becomes resolvable.
- **Atomicity is Powerful:** Using commands like `HINCRBY` and `ZINCRBY` simplifies code and prevents race conditions when updating counters or scores.
- **SCAN \> KEYS:** Learning to use `SCAN` (via `scan_iter` in Python) for finding keys in the cache inspector was crucial. `KEYS *` is simple but dangerous in production as it can block Redis.
- **Deployment Prep:** Refactoring the Redis connection logic to use environment variables (falling back to localhost) was key for deploying to Render using Redis Cloud credentials. Getting the `Procfile` right for `gunicorn` was also a necessary step.

One challenge was definitely iterating on the cache logic – realizing the initial negative cache check could hide a later positive result required rethinking the lookup order. Similarly, optimizing the `SCAN` loop on the Hashes page to use a single pipeline significantly improved efficiency.

---

## Conclusion

Building this DNS cache dashboard was a practical and engaging way to learn several core Redis data structures and caching patterns. It moved beyond theory and forced me to think about efficiency, data modeling, and even deployment concerns.

If you're learning Redis or Flask, I encourage you to check out the code on GitHub (link coming soon\!) or try building something similar yourself. It’s amazing how much you can learn by tackling a real-world problem, even a simplified version.

Happy caching\!
